{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "Hi. In This Chapter , we want to learn about some basics.\n",
    "now. first we import load_iris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "datas in sklearn are similar to dictionaries.lets analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "so there are 5 keys in the data dictionary. but what do they present?\n",
    "* data has all our real data. I mean Assume you find an iris flower and measure their sepals and petals size. in other word there are several rows that represent features in columns.\n",
    "* target is their target_name or in other word our output for each data rows.\n",
    "* Target_name is for represent how many kind of iris we have in this dataset.\n",
    "* DESCR is some description about this dataframe , mean , max , ...\n",
    "* feature_names is for show us each number in rows is for what? Or we can say they tell us what is this number in rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our columns name: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "our output names: ['setosa' 'versicolor' 'virginica'] \n",
      "first data row: [[5.1 3.5 1.4 0.2]]\n",
      "first 5 output: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"our columns name: {}\".format(dataset.feature_names))\n",
    "print(\"our output names: {} \".format(dataset.target_names))\n",
    "print(\"first data row: {}\".format(dataset.data[:1]))\n",
    "print(\"first 5 output: {}\".format(dataset.target[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beacause each row represent an iris type so it is a classification problem\n",
    "\n",
    "because we know each row is related to what kind of iris? (for example first 5 rows related to SETOSA) it is a supervised learning\n",
    "\n",
    "so until now we can say that this is a classification , supervised learning.\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "lets learn about dimensions and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension:(150, 4)\n",
      "target dimension:(150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"data dimension:{}\".format(dataset.data.shape))\n",
    "print(\"target dimension:{}\".format(dataset.target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so data always is an Matrix. and target is an array as big as data rows number\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a function that shuffles data and split it in 2 part.\n",
    "\n",
    "one part for training data , called \"Training Set\", and another part for check out our learning error measurment ,called \"Test Set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset.data , dataset.target , random_state=0 , test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets see train and test data shape or dimension :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train size : (112, 4) , Y train Size: (112,)\n",
      "X test size:(38, 4) , y test size:(38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train size : {} , Y train Size: {}\\nX test size:{} , y test size:{}\".format(X_train.shape , y_train.shape,X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle splits our data RANDOMLY.\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before training your machine learning model it is often a good idea to inspect the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first , lets tranfer date from numpy world into pandas world to use scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.9               3.0                4.2               1.5\n",
       "1                5.8               2.6                4.0               1.2\n",
       "2                6.8               3.0                5.5               2.1\n",
       "3                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe_train = pd.DataFrame(X_train , columns = dataset.feature_names)\n",
    "dataframe_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we create dataframe. so lets plot this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(dataframe_train, c = y_train,figsize=(10, 10),marker = \"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "LETS DIVE IN\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can start building the actual machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets start with k-near algorithm because it is very simple and easy to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this algorithm , to make a prediction for a new data point , the algorithm find the point in the training set that is closest to the new point. then it assigns the label of this training point to the new data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier(n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_neighbors is number of neighbors to use. we assign 1 to it.\n",
    "\n",
    "\n",
    "then we should train model or make it learn out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.fit(X_train , y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our mission is completed. model is ready to predict. so lets make two fake rows and see prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "new_data = [[5 , 2.9 , 1 , 0.2] , [1, 2,10, 1]];\n",
    "predict = kn.predict(new_data)\n",
    "print(dataset.target_names[predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but how much we can trust the result?  \n",
    "\n",
    "and thats where Test Set comes in. we can check model accuracy :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy by using score function: 0.974\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy by using score function: {:.3f}\".format(kn.score(X_test , y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD LUCK\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris();\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(data.data , data.target , test_size = 0.02);\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors = 1)\n",
    "model.fit(X_train , y_train);\n",
    "print(\"accuracy:{:0.2f}\".format(model.score(X_test , y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
